{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "set_reproducibility(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(\n",
    "            url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "\n",
    "def download_data(data_path, url_path, suffix):\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        print(\"Download completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(url):\n",
    "    with open(url, 'r') as json_file:\n",
    "    \tdata = json.load(json_file)['data']\n",
    "    \n",
    "    dataframe_rows = []\n",
    "\n",
    "    for x in data:\n",
    "        story = x['story']\n",
    "\n",
    "        for q, a in zip(x['questions'], x['answers']):\n",
    "            # if (a[\"span_text\"], a[\"span_start\"], a[\"span_end\"], a[\"input_text\"]) == (\"unknown\", -1, -1,\"unknown\"):\n",
    "            #     continue\n",
    "\n",
    "            question = q['input_text']\n",
    "            answer = a['input_text']\n",
    "            span_text = a['span_text']\n",
    "            span_start = a['span_start']\n",
    "            span_end = a['span_end']\n",
    "\n",
    "            # create single dataframe row\n",
    "            dataframe_row = {\n",
    "                \"story\": story,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"span_text\": span_text,\n",
    "                \"span_start\": span_start,\n",
    "                \"span_end\": span_end,\n",
    "            }\n",
    "\n",
    "            dataframe_rows.append(dataframe_row)\n",
    "\n",
    "    return pd.DataFrame(dataframe_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_df('./coqa/train.json')\n",
    "df_test = create_df('./coqa/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unanswerable questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['answer'] == 'unknown')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In same cases 'unknown' is the correct answer, so we remove only the one in which the spam text is 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['answer'] == 'unknown') & (df_train['span_text'] != 'unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = df_train.loc[(df_train['answer'] == 'unknown') & (df_train['span_text'] != 'unknown')].index\n",
    "index_test = df_test.loc[(df_test['answer'] == 'unknown') & (df_test['span_text'] != 'unknown')].index\n",
    "\n",
    "df_train.drop(index_train, inplace=True)\n",
    "df_test.drop(index_test, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset size: {df.shape}\")\n",
    "print(f\"Dataset columns: {df.columns.values}\")\n",
    "print(f\"Some examples: {df.iloc[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame(df)\n",
    "df_analysis['q_first_word']=df_analysis['question'].str.lower().str.extract(r'(\\w+)')\n",
    "df_analysis['q_first_two_words']=df_analysis['question'].str.lower().str.extract(r'^((?:\\S+\\s+){1}\\S+).*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top ranking first word in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.groupby('q_first_word').size().sort_values(ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top ranking first two words in question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.groupby('q_first_two_words').size().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of rielaborated or not rielaborated answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = []\n",
    "for i in range (len(df[\"story\"])):\n",
    "    sia.append(df[\"answer\"][i] in df[\"span_text\"][i])\n",
    "print(f'Percentage of rielaborated answers: {sia.count(False)/len(sia)*100:.2f}%')\n",
    "print(f'Percentage of not rielaborated answers: {sia.count(True)/len(sia)*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "081fbc05a628d22d111c7428c85ffa2f549f87b036631fc9cc920dbaeb12facd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
